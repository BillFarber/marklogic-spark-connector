plugins {
  id 'net.saliman.properties' version '1.5.2'
  id 'com.gradleup.shadow' version '8.3.3'
  id 'maven-publish'
}

configurations {
  // Defines all the implementation dependencies, but in such a way that they are not included as dependencies in the
  // library's pom.xml file. This is due to the shadow jar being published instead of a jar only containing this
  // project's classes. The shadow jar is published due to the need to relocate several packages to avoid conflicts
  // with Spark.
  shadowDependencies

  // This approach allows for all of the dependencies to be available for compilation and for running tests.
  compileOnly.extendsFrom(shadowDependencies)
}

dependencies {
  // This is compileOnly as any environment this is used in will provide the Spark dependencies itself.
  compileOnly('org.apache.spark:spark-sql_2.12:' + sparkVersion) {
    // Excluded from our ETL tool for size reasons, so excluded here as well to ensure we don't need it.
    exclude module: "rocksdbjni"
  }

  shadowDependencies project(":marklogic-spark-api")

  // Need this so that an OkHttpClientConfigurator can be created.
  // I think this is just compileOnly, since the classes are present via the Java Client?
  compileOnly 'com.squareup.okhttp3:okhttp:4.12.0'

  // Supports reading and writing RDF data.
  shadowDependencies("org.apache.jena:jena-arq:4.10.0") {
    exclude group: "com.fasterxml.jackson.core"
    exclude group: "com.fasterxml.jackson.dataformat"
  }

  // This will become a test-only dependency once we upgrade LangChain4j since that it requires Java 17.
  shadowDependencies project(":marklogic-langchain4j")
}

shadowJar {
  configurations = [project.configurations.shadowDependencies]

  // "all" is the default; no need for that in the connector filename. This also results in this becoming the library
  // artifact that is published as a dependency. That is desirable as it includes the relocated packages listed below,
  // which a dependent would otherwise have to manage themselves.
  archiveClassifier.set("")

  // Spark uses an older version of OkHttp; see
  // https://stackoverflow.com/questions/61147800/how-to-override-spark-jars-while-running-spark-submit-command-in-cluster-mode
  // for more information on why these are relocated.
  relocate "okhttp3", "com.marklogic.okhttp3"
  relocate "okio", "com.marklogic.okio"
}

// Publishing setup - see https://docs.gradle.org/current/userguide/publishing_setup.html .
java {
  withJavadocJar()
  withSourcesJar()
}

javadoc.failOnError = false
// Ignores warnings on params that don't have descriptions, which is a little too noisy
javadoc.options.addStringOption('Xdoclint:none', '-quiet')

publishing {
  publications {
    mainJava(MavenPublication) {
      pom {
        name = "${group}:${project.name}"
        description = "Spark 3 connector for MarkLogic"
        packaging = "jar"
        from components.java
        url = "https://github.com/marklogic/${project.name}"
        licenses {
          license {
            name = "The Apache License, Version 2.0"
            url = "http://www.apache.org/licenses/LICENSE-2.0.txt"
          }
        }
        developers {
          developer {
            id = "marklogic"
            name = "MarkLogic Github Contributors"
            email = "general@developer.marklogic.com"
            organization = "MarkLogic"
            organizationUrl = "https://www.marklogic.com"
          }
        }
        scm {
          url = "git@github.com:marklogic/${project.name}.git"
          connection = "scm:git@github.com:marklogic/${project.name}.git"
          developerConnection = "scm:git@github.com:marklogic/${project.name}.git"
        }
      }
    }
  }
  repositories {
    maven {
      if (project.hasProperty("mavenUser")) {
        credentials {
          username mavenUser
          password mavenPassword
        }
        url publishUrl
        allowInsecureProtocol = true
      } else {
        name = "central"
        url = mavenCentralUrl
        credentials {
          username mavenCentralUsername
          password mavenCentralPassword
        }
      }
    }
  }
}

task gettingStartedZip(type: Zip) {
  description = "Creates a zip of the getting-started project that is intended to be included as a downloadable file " +
    "on the GitHub release page."
  from "../examples/getting-started"
  exclude "build", ".gradle", "gradle-*.properties", ".venv", "venv", "docker"
  into "marklogic-spark-getting-started-${version}"
  archiveFileName = "marklogic-spark-getting-started-${version}.zip"
  destinationDirectory = file("build")
}
